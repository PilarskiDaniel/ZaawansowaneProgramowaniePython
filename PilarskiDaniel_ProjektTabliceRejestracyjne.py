# -*- coding: utf-8 -*-
"""test2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ledDfIoA_bDY-losjcN7AaO6yhNOOWsM
"""

#token API 53c60a58511ea8f23098a971e52a2e482b731dba
#app.platerecognizer.com

!pip install -U yolov5

import os
import time
import requests
import xml.etree.ElementTree as ET
import zipfile
from PIL import Image
import numpy as np
import yolov5
import cv2
import matplotlib.pyplot as plt
import torch

# Pobranie datasetu
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d piotrstefaskiue/poland-vehicle-license-plate-dataset

with zipfile.ZipFile("poland-vehicle-license-plate-dataset.zip", 'r') as zip_ref:
    zip_ref.extractall("dataset")

# Inicjalizacja modelu YOLO
model = yolov5.load('keremberke/yolov5m-license-plate')
model.conf = 0.60
model.iou = 0.45
model.agnostic = False
model.multi_label = False
model.max_det = 10

image_path = '/content/dataset/photos/194.jpg'
img_pil = Image.open(image_path).convert("RGB")
img_np = np.array(img_pil).copy()  # kopiujemy, aby by≈Ç writeable
results = model(img_np, size=640)

# Wy≈õwietlenie detekcji
results.show()

# Wczytanie anotacji
def load_cvat_annotations(xml_path):
    tree = ET.parse(xml_path)
    root = tree.getroot()
    annotations = {}
    for image_tag in root.iter('image'):
        name = image_tag.attrib['name']
        width = int(image_tag.attrib['width'])
        height = int(image_tag.attrib['height'])
        for box_tag in image_tag.iter('box'):
            if box_tag.attrib['label'] == 'plate':
                xtl = float(box_tag.attrib['xtl'])
                ytl = float(box_tag.attrib['ytl'])
                xbr = float(box_tag.attrib['xbr'])
                ybr = float(box_tag.attrib['ybr'])
                for attr in box_tag.iter('attribute'):
                    if attr.attrib['name'] == 'plate number':
                        plate_number = attr.text.strip()
                annotations[name] = {
                    'bbox': (xtl, ytl, xbr, ybr),
                    'size': (width, height),
                    'plate_number': plate_number
                }
    return annotations

# API KEY do PlateRecognizer
PLATE_RECOGNIZER_TOKEN = "53c60a58511ea8f23098a971e52a2e482b731dba"

def detect_and_alpr(image_path, model):
    img = Image.open(image_path).convert("RGB")
    img_np = np.array(img)

    results = model(img_np, size=640)
    predictions = results.pred[0]

    if predictions.shape[0] == 0:
        return None

    x1, y1, x2, y2 = map(int, predictions[0, :4])
    crop = img_np[y1:y2, x1:x2]

    _, im_buf = cv2.imencode('.jpg', crop)
    files = {'upload': ('image.jpg', im_buf.tobytes(), 'image/jpeg')}
    headers = {'Authorization': f'Token {PLATE_RECOGNIZER_TOKEN}'}

    response = requests.post(
        'https://api.platerecognizer.com/v1/plate-reader/',
        files=files,
        headers=headers
    )

    result_json = response.json()

    if 'results' in result_json and len(result_json['results']) > 0:
        return result_json['results'][0]['plate'].upper()
    else:
        return None

def show_cropped_plate(image_path, model):
    img = Image.open(image_path).convert("RGB")
    img_np = np.array(img)

    results = model(img_np, size=640)
    predictions = results.pred[0]

    if predictions.shape[0] == 0:
        print("Brak wykryƒá.")
        return

    x1, y1, x2, y2 = map(int, predictions[0, :4])
    crop = img_np[y1:y2, x1:x2]

    # Poka≈º wyciƒôty fragment
    plt.imshow(crop)
    plt.title("Wycinek detekcji")
    plt.axis('off')
    plt.show()

image_path = '/content/dataset/photos/10.jpg'

show_cropped_plate(image_path, model)
# Wywo≈Çaj funkcjƒô
plate = detect_and_alpr(image_path, model)

# Wypisz wynik
print("Wykryta tablica:", plate)

# Weryfikacja
xml_path = '/content/dataset/annotations.xml'
image_dir = '/content/dataset/photos'
annotations = load_cvat_annotations(xml_path)

image_files = sorted(os.listdir(image_dir))[:100]
total = len(image_files)
correct = 0
start_time = time.time()

for i, file in enumerate(image_files):
    path = os.path.join(image_dir, file)
    prediction = detect_and_alpr(path, model)
    true_plate = annotations.get(file, {}).get('plate_number', None)

    if prediction and true_plate:
        pred_clean = prediction.replace(" ", "").upper()
        true_clean = true_plate.replace(" ", "").upper()
        if pred_clean == true_clean:
            correct += 1

    print(f"[{i+1}/{total}] Plik: {file}")
    print(f"ALPR: {prediction} | GT: {true_plate}")
    print("-" * 50)

end_time = time.time()

accuracy = correct / total
print("\nüìä Wyniki ko≈Ñcowe:")
print(f"‚úÖ Dok≈Çadno≈õƒá: {accuracy*100:.2f}%")
print(f"‚è±Ô∏è Czas przetworzenia 100 obraz√≥w: {end_time - start_time:.2f} s")